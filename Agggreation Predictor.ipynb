{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3163cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from utils.utils import load_data_set, gen_batch_sequence\n",
    "from model.wordEmbedding import WordEmbedding\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d535aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train dataset\n",
      "Loaded 56355 queries and 18585 tables\n"
     ]
    }
   ],
   "source": [
    "train_query, train_table = load_data_set('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c1f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_query_id = [34,56,12,43] #random\n",
    "ret_tup = gen_batch_sequence(train_query,train_table,selected_query_id, 0, len(selected_query_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "404ced24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['during', 'which', 'years', 'was', 'marcus', 'banks', 'in', 'toronto', '?'], ['what', 'is', 'the', 'canton', 'of', 'grande', 'dixence', '?'], ['what', 'school', 'did', 'player', 'number', '6', 'come', 'from', '?'], ['what', 'time', 'was', 'the', 'highest', 'for', '2nd', 'finishers', '?']]\n"
     ]
    }
   ],
   "source": [
    "batch_query = ret_tup[0]\n",
    "batch_table = ret_tup[1]\n",
    "gt_quety = ret_tup[4]\n",
    "print(batch_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73519a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "word_emb = WordEmbedding('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38d2ca2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(word_emb.bert_model.config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eec46ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('During which years was Marcus Banks in Toronto?', ['Player', 'No.', 'Nationality', 'Position', 'Years in Toronto', 'School/Club Team'], 'SELECT years in toronto FROM table_ WHERE player EQL marcus banks'), ('What is the canton of grande dixence?', ['Name', 'Canton', 'Height (meters)', 'Crest length (meters)', 'Type', 'Year of construction', 'Name of the Lake'], 'SELECT canton FROM table_ WHERE name EQL grande dixence'), ('What school did player number 6 come from?', ['Player', 'No.', 'Nationality', 'Position', 'Years in Toronto', 'School/Club Team'], 'SELECT school/club team FROM table_ WHERE no . EQL 6'), ('What time was the highest for 2nd finishers?', ['Year', 'Tournaments played', 'Cuts made*', 'Wins', '2nd', 'Top 10s', 'Best finish', 'Earnings ($)', 'Money list rank', 'Scoring average', 'Scoring rank'], 'SELECT max ( 2nd ) FROM table_ WHERE')]\n"
     ]
    }
   ],
   "source": [
    "q_seq, col_seq, col_num, ans_seq, query_seq, ground_truth_cond_seq, raw_data = \\\n",
    "        gen_batch_sequence(train_query, train_table,selected_query_id,0,len(selected_query_id))\n",
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fba1c1",
   "metadata": {},
   "source": [
    "## Function for running LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6909140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 47, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_op, input_lens = word_emb.gen_x_batch(batch_query, batch_table)\n",
    "x_emb = bert_op.last_hidden_state\n",
    "x_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2061717a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_op.pooler_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d289c417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(768, 50, num_layers=4, bidirectional=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = nn.LSTM(768,hidden_size = 100//2, num_layers = 4,bidirectional=True)\n",
    "\n",
    "lstm.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "475e790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_n, (c_fwd, c_rev) = lstm(x_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ccf8830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_n: torch.Size([4, 47, 100])\n",
      "c_wd: torch.Size([8, 47, 50])\n",
      "c_rev: torch.Size([8, 47, 50])\n"
     ]
    }
   ],
   "source": [
    "print(f\"h_n: {h_n.shape}\\nc_wd: {c_fwd.shape}\\nc_rev: {c_rev.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6931dc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  in the code for the reference paper they sorted the inputs (acc. to the size)\n",
    "# TODO: Clean this function: \n",
    "def run_lstm(lstm, inp, inp_length, prev_hidden=None):\n",
    "    '''\n",
    "    Input: This function takes in 3 arguments \n",
    "        lstm : the name of the lstm variable that needs to be run\n",
    "        inp  : the input in the for [Batch size , num_tok, last_layer]\n",
    "        inp_length: an array that contains the length of each element in the batch size = batch size\n",
    "        pre_hidden: hidden layer values of the previous lstm layer\n",
    "    \n",
    "    Ouptut: \n",
    "        Same as nn.LSTM\n",
    "    '''\n",
    "    ret_h, ret_c = lstm(inp,prev_hidden)\n",
    "    return ret_h, ret_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49713437",
   "metadata": {},
   "source": [
    "## Attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52409987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3,4,5,6]])\n",
    "x = x.squeeze()\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "426da097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= torch.tensor([[[1,2,3,4],\n",
    "                  [5,6,7,8]],\n",
    "                [[9,10,11,12],\n",
    "                 [13,14,15,16]],\n",
    "                [[9,10,11,12],\n",
    "                 [13,14,15,16]]\n",
    "                ]).to('cuda')\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "363cf687",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6237597f",
   "metadata": {},
   "source": [
    "### Scalar attention score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54216a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_attention = nn.Linear(num_hidden, 1).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e1f9d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 47])\n"
     ]
    }
   ],
   "source": [
    "att_val = scalar_attention(h_n)\n",
    "att_val = att_val.squeeze()\n",
    "print(att_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13f3b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_x_len = max(input_lens)\n",
    "for idx, num in enumerate(input_lens): # reduce the importance of 0 values\n",
    "    if num < max_x_len:\n",
    "        att_val[idx,num:] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bab90e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 47])\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1) # Probability distribution for the attention values\n",
    "att = softmax(att_val)\n",
    "print(att.shape)\n",
    "\n",
    "for x in att:\n",
    "    assert int(x.sum().ceil().tolist()) == 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfd01bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 47, 100])\n",
      "torch.Size([4, 47, 100])\n",
      "torch.Size([4, 100])\n"
     ]
    }
   ],
   "source": [
    "print(h_n.shape)\n",
    "att_matrix = att.unsqueeze(2).expand_as(h_n)\n",
    "print(att_matrix.shape)\n",
    "K_agg = (h_n*att_matrix).sum(1)\n",
    "print(K_agg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c7cd356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 100])\n"
     ]
    }
   ],
   "source": [
    "print(att_matrix[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd7cda90",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_out = nn.Sequential(\n",
    "            nn.Linear(num_hidden,num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, 6)\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36b12a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0924, -0.0693, -0.1062, -0.1177,  0.0166, -0.0138],\n",
      "        [ 0.0932, -0.0712, -0.1023, -0.1223,  0.0198, -0.0156],\n",
      "        [ 0.0926, -0.0736, -0.0985, -0.1263,  0.0206, -0.0199],\n",
      "        [ 0.0901, -0.0777, -0.0945, -0.1282,  0.0180, -0.0265]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "agg_score = agg_out(K_agg)\n",
    "print(agg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733c20c3",
   "metadata": {},
   "source": [
    "## Class for aggregation predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8eae0348",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AggregationPredictor(nn.Module):\n",
    "    def __init__(self,input_layer,hidden_size,num_layers,gpu):\n",
    "        super(AggregationPredictor,self).__init__()\n",
    "        self.agg_lstm = nn.LSTM(input_size=input_layer, hidden_size=hidden_size // 2,\n",
    "                                num_layers=num_layers, batch_first=True,\n",
    "                                dropout=0.3, bidirectional=True)\n",
    "        \n",
    "        self.agg_att = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "        self.soft_max = nn.softmax()\n",
    "        self.agg_out = nn.Sequential(\n",
    "            nn.Linear(input_size = hidden_size, out_features=hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(input_size , hidden_size, 6)\n",
    "        )\n",
    "        \n",
    "        if(gpu):\n",
    "            self.agg_lstm = self.agg_lstm.to('cuda')\n",
    "            self.agg_att  = self.agg_att.to('cuda')\n",
    "            self.soft_max = self.soft_max.to('cuda')\n",
    "            self.agg_out  = self.agg_out.to('cuda')\n",
    "    \n",
    "    def forward(x_input, x_len):\n",
    "        B = x_input.shape[0]\n",
    "        max_len = max(x_len)\n",
    "        h_n, _ = run_lstm(agg.lstm,agg.lstm.shape[1]) # [B * longestinput * hidden_size] \n",
    "        \n",
    "        #calculate the scalar attention score. [scalar, since one value for each input word.]\n",
    "        att_val = self.agg_att(h_n)  #[B * longest_input * 1]\n",
    "        att_val = att_val.squeeze()  #[B* longest_input]\n",
    "        \n",
    "        for index, l in x_len:\n",
    "            if(l<max_len):\n",
    "                att_val = att_val[index][l:] = -100\n",
    "        \n",
    "        att_prob_dist = self.soft_max(att_val) #[B * longest_input]\n",
    "        att_prob_dist = att_prob_dist.unsqueeze(2).expand_as(h_n) #[B * longest_input * hidden_size]\n",
    "        K_agg = (h_n* att_prob_dist).sum(1)\n",
    "        agg_score = self.agg_out(K_agg)\n",
    "        return agg_score\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e423a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SQL(nn.Module):\n",
    "    def __init__(self, bert_model_name, hidden_size, num_depth ):\n",
    "        super(Seq2SQL,self).__init__()\n",
    "        \n",
    "        self.gpu = torch.cuda.is_available()\n",
    "        if(hidden_size&1!=0):\n",
    "            raise ValueError('hidden size must be even, since this is a bidirectional network')\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.word_emb   = WordEmbedding(bert_model_name)\n",
    "        self.word_emb_size = self.word_emb.bert_model.config.hidden_size\n",
    "        self.aggregator = AggregationPredictor(input_layer=self.word_emb_size, \n",
    "                                              hidden_size=hidden_size,num_layers = num_depth,gpu=True)\n",
    "        self.CE = nn.CrossEntropyLoss()\n",
    "        if(torch.cuda.is_available):\n",
    "            self.to('cuda')\n",
    "        \n",
    "    def forward(self,queries, col):\n",
    "        x_embed, x_lengths = self.word_emb.gen_x_batch(q_batch=queries,col_batch=col)\n",
    "        \n",
    "        agg_score = self.word_emb(x_embed, x_lengths)\n",
    "        \n",
    "        return (agg_score,)\n",
    "    \n",
    "    def loss(self, score):\n",
    "        agg_score = score[0]\n",
    "        loss = 0\n",
    "        \n",
    "        loss += self.CE(agg_score)\n",
    "        return loss   \n",
    "    \n",
    "    def gen_query(self, score,query_batch, col_batch, raw_query, raw_col):\n",
    "        agg_score = score\n",
    "        B= len(query_batch)\n",
    "        for b in range(B):\n",
    "            print(score)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9077b90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train dataset\n",
      "Loaded 56355 queries and 18585 tables\n",
      "Loading dev dataset\n",
      "Loaded 8421 queries and 2716 tables\n"
     ]
    }
   ],
   "source": [
    "train_queries, train_tables = load_data_set('train')\n",
    "val_queries, val_tables = load_data_set('dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "122da03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_train(model, optimizer,batch_size, sql_queries, table_data):\n",
    "    model.train()\n",
    "    num_queries = len(sql_queries)\n",
    "    perm = np.random.permutation(num_queries)\n",
    "    cumulative_loss = 0.0\n",
    "    start = 0\n",
    "\n",
    "    while start< num_queries:\n",
    "        end = start + batch_size if start + batch_size < len(perm) else len(perm)\n",
    "\n",
    "        q_seq, col_seq, col_num, ans_seq, query_seq, ground_truth_cond_seq, raw_data = \\\n",
    "            generate_batch_sequence(sql_data, table_data, perm, start, end)\n",
    "        \n",
    "        score = model(q_seq, col_seq)\n",
    "        loss = model.loss(score)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        start = end\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1e1a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_query(sql_data, idxes, start, end):\n",
    "    query_gt = []\n",
    "    table_ids = []\n",
    "    for i in range(start, end):\n",
    "        query_gt.append(sql_data[idxes[i]]['sql'])\n",
    "        table_ids.append(sql_data[idxes[i]]['table_id'])\n",
    "    return query_gt, table_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d154d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 4, 1, (0,), (0,))\n"
     ]
    }
   ],
   "source": [
    "print(ans_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0243c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_query(sql_data, idx, start, end):\n",
    "    query_gt = []\n",
    "    table_id = []\n",
    "    for i in range(start,end):\n",
    "        query_gt.append(sql_data[idx[i]]['sql'])\n",
    "        table_id.append(sql_data[idx[i]]['table_id'])\n",
    "    return query_gt, table_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ceca3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_acc(model, batch_size, sql_data, table_data, save_results = False):\n",
    "    model.eval()\n",
    "    perm = list(range(len(sql_data)))\n",
    "    start = 0\n",
    "    one_acc_num = 0.0\n",
    "    while start < len(sql_data):\n",
    "        end = start + batch_size if start + batch_size < len(perm) else len(perm)\n",
    "\n",
    "        q_seq, col_seq, col_num, ans_seq, query_seq, ground_truth_cond_seq, raw_data =\\\n",
    "            generate_batch_sequence(sql_data, table_data, perm, start, end)\n",
    "        \n",
    "        raw_q_seq = [x[0] for x in raw_data]\n",
    "        raw_col_seq = [x[1] for x in raw_data]\n",
    "        \n",
    "        query_gt, table_ids = generate_batch_query(sql_data, perm, start, end)\n",
    "        ground_truth_sel_seq = [x[1] for x in ans_seq]\n",
    "        \n",
    "        score = model.forward(q_seq, col_seq, col_num, ground_truth_sel=ground_truth_sel_seq)\n",
    "        pred_queries = model.gen_query(score, q_seq, col_seq,\n",
    "                                       raw_q_seq, raw_col_seq)\n",
    "        one_err, tot_err = model.check_accuracy(pred_queries, query_gt)\n",
    "        \n",
    "#         if save_results:\n",
    "#             model.save_readable_results(pred_queries, query_gt, table_ids, table_data)\n",
    "\n",
    "        one_acc_num += (end - start - one_err)\n",
    "        tot_acc_num += (end - start - tot_err)\n",
    "\n",
    "        start = end\n",
    "    return tot_acc_num / len(sql_data), one_acc_num / len(sql_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "035eb3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'softmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m TRAINING_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      3\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSeq2SQL\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert-base-uncased\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(),lr\u001b[38;5;241m=\u001b[39mLEARNING_RATE)\n\u001b[1;32m      8\u001b[0m epoch_loses \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[50], line 12\u001b[0m, in \u001b[0;36mSeq2SQL.__init__\u001b[0;34m(self, bert_model_name, hidden_size, num_depth)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_emb   \u001b[38;5;241m=\u001b[39m WordEmbedding(bert_model_name)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_emb_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_emb\u001b[38;5;241m.\u001b[39mbert_model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhidden_size\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregator \u001b[38;5;241m=\u001b[39m \u001b[43mAggregationPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_emb_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCE \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available):\n",
      "Cell \u001b[0;32mIn[52], line 9\u001b[0m, in \u001b[0;36mAggregationPredictor.__init__\u001b[0;34m(self, input_layer, hidden_size, num_layers, gpu)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_lstm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLSTM(input_size\u001b[38;5;241m=\u001b[39minput_layer, hidden_size\u001b[38;5;241m=\u001b[39mhidden_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      5\u001b[0m                         num_layers\u001b[38;5;241m=\u001b[39mnum_layers, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m                         dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, bidirectional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_att \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(in_features\u001b[38;5;241m=\u001b[39mhidden_size, out_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoft_max \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_out \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m     11\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(input_size \u001b[38;5;241m=\u001b[39m hidden_size, out_features\u001b[38;5;241m=\u001b[39mhidden_size),\n\u001b[1;32m     12\u001b[0m     nn\u001b[38;5;241m.\u001b[39mTanh(),\n\u001b[1;32m     13\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(input_size , hidden_size, \u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(gpu):\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'softmax'"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1e-5\n",
    "TRAINING_EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "model = Seq2SQL('bert-base-uncased',100,2)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=LEARNING_RATE)\n",
    "\n",
    "epoch_loses = []\n",
    "i = 0;\n",
    "#for i in range(TRAINING_EPOCHS):\n",
    "print(f\"Epoch {i+1}\")\n",
    "\n",
    "epoch_loss = epoch_train(model, optimizer, BATCH_SIZE, train_queries, train_tables)\n",
    "epoch_loses.append(epoch_loss)\n",
    "\n",
    "print(f\"Loss : {epoch_loss}\")\n",
    "\n",
    "training_accuracy = epoch_acc(model, BATCH_SIZE, sql_data, table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6a6d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801af23a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
